{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "import torchaudio\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset_generation.randomDataset import RandomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.codec import CodecTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, x_len, y_len):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-x_len-y_len- 1):\n",
    "        _x = data[i:(i+x_len)]\n",
    "        _y = data[i+x_len:i+x_len+y_len]\n",
    "        x.append(_x)\n",
    "        #print(_x.shape) \n",
    "        #print(_y.shape)\n",
    "        y.append(_y)\n",
    "\n",
    "    x = torch.tensor(data=x)\n",
    "    y = torch.tensor(data=y)\n",
    "    return x.unsqueeze(2), y.unsqueeze(2)\n",
    "\n",
    "test = np.zeros(1000)\n",
    "x, y = sliding_windows(test, 10, 5)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x)\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "src = '../dataset_generation/speeches'\n",
    "nfft=512\n",
    "nmels=60\n",
    "#mfcc = torchaudio.transforms.MFCC(sample_rate=16000, n_mfcc=15, melkwargs={'n_fft':nfft, 'n_mels':nmels})\n",
    "codec = CodecTransform(sample_rate=16000, bandwidth=6.0)\n",
    "dataSet = RandomDataset(src, 16000, 1000, codec, 50, 49)\n",
    "train_data, val_data = torch.utils.data.random_split(dataSet, (800, 200))\n",
    "train_dl = DataLoader(train_data, batch_size=64)\n",
    "val_dl = DataLoader(val_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set \n",
    "input_waveform = dataSet[0][0]\n",
    "# assume they're returned separately \n",
    "first_row = input_waveform[0, 0, :].numpy()\n",
    "trainX, trainY = sliding_windows(first_row, 8, 4) \n",
    "# (N, 10)\n",
    "trainX = Variable(torch.Tensor(trainX))\n",
    "trainY = Variable(torch.Tensor(trainY))\n",
    "# (N, 5)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 4 # Predict next 5 outputs \n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class EncodecDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_X, data_Y):\n",
    "        super().__init__()\n",
    "        self.data_X = data_X\n",
    "        self.data_Y = data_Y\n",
    "        self.dataset_size = len(data_X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # which file to take a random clip from\n",
    "        if torch.is_tensor(index): \n",
    "            index = index.tolist()\n",
    "            \n",
    "        x_values = data_X[index]\n",
    "        y_values = data_Y[index]\n",
    "        return x_values, y_values\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load da data \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "x_datapath = \"../dataset_generation/encodec_data/trainX.npy\"\n",
    "y_datapath = \"../dataset_generation/encodec_data/trainY.npy\"\n",
    "trainX = np.load(x_datapath, allow_pickle = True)[:, 0, :]\n",
    "input_dim = 10\n",
    "hidden_dim = 5\n",
    "output_dim = 1\n",
    "print(np.expand_dims(trainX, axis = 1).shape, trainY.shape)\n",
    "random_stuffs = np.random.choice(np.arange(trainX.shape[0]), 1000)\n",
    "random_stuffs = trainX[random_stuffs]\n",
    "data_X = []\n",
    "data_Y = []\n",
    "\n",
    "for now in random_stuffs: \n",
    "    # Run sliding window \n",
    "    x, y = sliding_windows(now, input_dim, output_dim)\n",
    "    if len(data_X) == 0: \n",
    "        data_X = x\n",
    "    else: \n",
    "        data_X = torch.cat((data_X, x))\n",
    "    if len(data_Y) == 0: \n",
    "        data_Y = y\n",
    "    else: \n",
    "        data_Y = torch.cat((data_Y, y))\n",
    "    #print(data_X.shape, data_Y.shape)\n",
    "    \n",
    "data_X = data_X.squeeze()\n",
    "data_Y = data_Y.squeeze()\n",
    "\n",
    "# Try dataloader \n",
    "data_actual = EncodecDataset(data_X, data_Y)\n",
    "data_generator = DataLoader(data_actual, batch_size = 363, shuffle = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt4_architectures import AutoregressiveTransformer\n",
    "transformer = AutoregressiveTransformer(input_dim, hidden_dim, output_dim)\n",
    "transformer.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "print(\"hi\")\n",
    "n_batches = int(len(data_X)/363)\n",
    "i = 0\n",
    "for epoch in range(num_epochs): \n",
    "    for local_batch, local_labels in data_generator:\n",
    "        \n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.unsqueeze(axis = 1).to(device), local_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transformer(local_batch)\n",
    "        \n",
    "        loss = criterion(outputs, local_labels.unsqueeze(axis = 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0: \n",
    "            print(f\"batch {i}: {loss.item()}\")\n",
    "        i += 1\n",
    "    '''\n",
    "    # JUst do  batches manually for now\n",
    "    for i in range(int(n_batches)): \n",
    "        \n",
    "        current_X, current_Y = data_X[i*n_batches:(i+1)*n_batches], data_Y[i*n_batches:(i+1)*n_batches]\n",
    "        outputs = transformer(current_X.unsqueeze(axis =1))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, data_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()'''\n",
    "        \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "      print(f\"EPOCH {epoch}: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    #WE ARE HERE\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    #print(outputs.shape)\n",
    "    trainY=trainY.squeeze()\n",
    "    #print(trainY.shape)\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_X[1].shape)\n",
    "startingInput = data_X[300]\n",
    "total_pred_points = 1500\n",
    "current = 0\n",
    "\n",
    "for local_batch, local_labels in data_generator: \n",
    "    local_batch = local_batch.unsqueeze(axis = 1)\n",
    "    print(local_batch, local_batch.shape)\n",
    "    break\n",
    "transformer.eval()\n",
    "currentInput = torch.Tensor()\n",
    "\n",
    "currentInput = torch.cat((currentInput.to(device), startingInput.to(device)))\n",
    "currentInput = currentInput.unsqueeze(axis = 0).unsqueeze(axis = 1)\n",
    "print(currentInput.shape)\n",
    "predictedWaveform = currentInput\n",
    "\n",
    "while current < total_pred_points: \n",
    "    nextSamples = transformer(currentInput)\n",
    "    current += len(nextSamples)\n",
    "    #print(nextSamples.shape)\n",
    "    predictedWaveform = torch.cat((predictedWaveform, nextSamples.unsqueeze(axis = 0)), dim = 2)\n",
    "    #print(predictedWaveform.shape)\n",
    "    currentInput = predictedWaveform[:, :, :10]\n",
    "    \n",
    "print(\"done\")\n",
    "print(predictedWaveform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION STUFF \n",
    "# start with sample of 10 from some waveform \n",
    "\n",
    "\n",
    "startingInput = data_X[30:38]\n",
    "#startingInput = waveform[30:40] #Random cliup of  010 saneomes in waveform \n",
    "totalPredictionPoints = 2000\n",
    "current = 0 \n",
    "currentInput = torch.tensor(data=startingInput).unsqueeze(0).unsqueeze(2)\n",
    "predictedWaveform = currentInput.squeeze()\n",
    "print()\n",
    "lstm.eval()\n",
    "while current < totalPredictionPoints: \n",
    "  nextSamples = lstm.forward(currentInput).squeeze()\n",
    "  predictedWaveform=torch.cat((predictedWaveform, nextSamples), dim=0)\n",
    "  current += num_classes # total length of predicted waveform \n",
    "  currentInput = predictedWaveform[-10:].unsqueeze(0).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictedWaveform.shape)\n",
    "from encodec import EncodecModel\n",
    "model = EncodecModel.encodec_model_24khz()\n",
    "model.set_target_bandwidth(6.0)\n",
    "test = predictedWaveform.cpu().squeeze(0).long().squeeze(0).unsqueeze(1).clip(min = 0, max = 1024)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictedWaveform.unsqueeze(0).long().unsqueeze(1).clip(min=0, max=1024)\n",
    "print(p.shape)\n",
    "with torch.no_grad():\n",
    "    reconstruction = model.decode([(predictedWaveform.cpu().long(), None)])[0]\n",
    "\n",
    "import IPython\n",
    "IPython.display.Audio(reconstruction[0], rate = model.sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictedWaveform[:, :, 300:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
